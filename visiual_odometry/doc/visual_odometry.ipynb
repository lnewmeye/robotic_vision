{
 "metadata": {
  "name": "",
  "signature": "sha256:1eef5ac6534e46faa7a188da4b54c291c7f132efc8799e6518521efa8d3f0fa3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Visual Odometry\n",
      "This script is for finding and ploting the estimated path from the rotation and translation matricies computed in OpenCV C++ code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import animation as anm\n",
      "from matplotlib import image as img\n",
      "from numpy.linalg import inv\n",
      "#%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 321
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Ground Truth Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load truth data from file\n",
      "vo_practice_truth = np.genfromtxt('../data/vo_practice_sequence_truth.txt', delimiter=' ')\n",
      "\n",
      "# Load truth data into list of matricies\n",
      "motion = []\n",
      "for row in vo_practice_truth:\n",
      "    M = np.empty([4, 4])\n",
      "    M[0, 0] = row[0];\n",
      "    M[0, 1] = row[1];\n",
      "    M[0, 2] = row[2];\n",
      "    M[0, 3] = row[3];\n",
      "    M[1, 0] = row[4];\n",
      "    M[1, 1] = row[5];\n",
      "    M[1, 2] = row[6];\n",
      "    M[1, 3] = row[7];\n",
      "    M[2, 0] = row[8];\n",
      "    M[2, 1] = row[9];\n",
      "    M[2, 2] = row[10];\n",
      "    M[2, 3] = row[11];\n",
      "    M[3, 0] = 0;\n",
      "    M[3, 1] = 0;\n",
      "    M[3, 2] = 0;\n",
      "    M[3, 3] = 1;\n",
      "    motion.append(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start from point 0,0\n",
      "X = np.array([0, 0, 0, 1])\n",
      "X.shape = (4,1)\n",
      "\n",
      "# Create lists for x and y coordinates\n",
      "x_truth = []\n",
      "y_truth = []\n",
      "z_truth = []\n",
      "\n",
      "# Iterate over motion\n",
      "for M in motion:\n",
      "    P = np.matmul(M, X)\n",
      "    x_truth.append(P[0,0])\n",
      "    y_truth.append(P[1,0])\n",
      "    z_truth.append(P[2,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Visual Odometry Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load odometry data from file\n",
      "vo_practice_data = np.genfromtxt('../output/vo_practice_sequence_data.txt', delimiter=' ')\n",
      "\n",
      "# Load truth data into list of matricies\n",
      "motion = []\n",
      "for row in vo_practice_data:\n",
      "    M = np.empty([4, 4])\n",
      "    M[0, 0] = row[0];\n",
      "    M[0, 1] = row[1];\n",
      "    M[0, 2] = row[2];\n",
      "    M[0, 3] = row[3];\n",
      "    M[1, 0] = row[4];\n",
      "    M[1, 1] = row[5];\n",
      "    M[1, 2] = row[6];\n",
      "    M[1, 3] = row[7];\n",
      "    M[2, 0] = row[8];\n",
      "    M[2, 1] = row[9];\n",
      "    M[2, 2] = row[10];\n",
      "    M[2, 3] = row[11];\n",
      "    M[3, 0] = 0;\n",
      "    M[3, 1] = 0;\n",
      "    M[3, 2] = 0;\n",
      "    M[3, 3] = 1;\n",
      "    motion.append(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create initial camera pose\n",
      "C = np.identity(4)\n",
      "\n",
      "# Create list for saving poses\n",
      "poses = []\n",
      "\n",
      "# Iterate over motion\n",
      "for M in motion:\n",
      "    C = np.matmul(C, inv(M))\n",
      "    #C = np.matmul(C, M)\n",
      "    poses.append(C)\n",
      "\n",
      "# Create lists for x and y coordinates\n",
      "x_odometry = []\n",
      "y_odometry = []\n",
      "z_odometry = []\n",
      "\n",
      "# Start from point 0,0\n",
      "X = np.array([0, 0, 0, 1])\n",
      "X.shape = (4,1)\n",
      "\n",
      "for M in poses:\n",
      "    P = np.matmul(M, X)\n",
      "    #P = np.matmul(inv(M), X)\n",
      "    x_odometry.append(P[2,0])\n",
      "    y_odometry.append(P[1,0])\n",
      "    z_odometry.append(-P[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot data\n",
      "fig, (ax) = plt.subplots(1, 1, figsize=(9,6))\n",
      "ax.plot(x_truth, z_truth, 'ro', label='Ground Truth')\n",
      "ax.plot(x_odometry, z_odometry, 'bo', label='Odometry Data')\n",
      "\n",
      "# Label plot\n",
      "ax.set_title('Visual Odometry Track (Practice)')\n",
      "ax.set_xlabel('x')\n",
      "ax.set_ylabel('z')\n",
      "ax.legend()\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 361
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Animate Results with Images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define animation properties\n",
      "frame_length = len(x_odometry)\n",
      "frame_period = 10\n",
      "\n",
      "# Define names of images\n",
      "def getImageName(image_number):\n",
      "    if image_number < 10:\n",
      "        return \"../output/vo_practice_sequence/00000\" + str(image_number) + \".png\"\n",
      "    elif image_number < 100:\n",
      "        return \"../output/vo_practice_sequence/0000\" + str(image_number) + \".png\"\n",
      "    return \"../output/vo_practice_sequence/000\" + str(image_number) + \".png\"\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18,6))\n",
      "line1, = ax1.plot([], [], 'ro', label='Ground Truth')\n",
      "line2, = ax1.plot([], [], 'bo', label='Odometry Data')\n",
      "#fig = plt.figure()\n",
      "image_number = 0;\n",
      "image_plot = plt.imshow(img.imread(getImageName(image_number)), animated=True)\n",
      "ax1.set_ylim([0, 500])\n",
      "ax1.set_xlim([-300, 300])\n",
      "\n",
      "def updatefig(i):\n",
      "    global image_number\n",
      "    image_number = image_number + 1\n",
      "    image_plot.set_array(img.imread(getImageName(image_number)))\n",
      "    line1.set_data(x_truth[0:i], z_truth[0:i])\n",
      "    line2.set_data(x_odometry[0:i], z_odometry[0:i])\n",
      "    return image_plot, line1, line2,\n",
      "\n",
      "image_animation = anm.FuncAnimation(fig, updatefig, interval=frame_period, blit=True,\n",
      "                                    frames=frame_length)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Exception in Tkinter callback\n",
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1540, in __call__\n",
        "    return self.func(*args)\n",
        "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 590, in callit\n",
        "    func(*args)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py\", line 147, in _on_timer\n",
        "    TimerBase._on_timer(self)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/backend_bases.py\", line 1305, in _on_timer\n",
        "    ret = func(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 1021, in _step\n",
        "    still_going = Animation._step(self, *args)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 827, in _step\n",
        "    self._draw_next_frame(framedata, self._blit)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 845, in _draw_next_frame\n",
        "    self._pre_draw(framedata, blit)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 858, in _pre_draw\n",
        "    self._blit_clear(self._drawn_artists, self._blit_cache)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 898, in _blit_clear\n",
        "    a.figure.canvas.restore_region(bg_cache[a])\n",
        "KeyError: <matplotlib.axes._subplots.AxesSubplot object at 0x7fee5dd89750>\n",
        "Exception in Tkinter callback"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1540, in __call__\n",
        "    return self.func(*args)\n",
        "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 590, in callit\n",
        "    func(*args)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.py\", line 147, in _on_timer\n",
        "    TimerBase._on_timer(self)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/backend_bases.py\", line 1305, in _on_timer\n",
        "    ret = func(*args, **kwargs)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 1021, in _step\n",
        "    still_going = Animation._step(self, *args)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 827, in _step\n",
        "    self._draw_next_frame(framedata, self._blit)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 846, in _draw_next_frame\n",
        "    self._draw_frame(framedata)\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/animation.py\", line 1212, in _draw_frame\n",
        "    self._drawn_artists = self._func(framedata, *self._args)\n",
        "  File \"<ipython-input-362-d979621f5de1>\", line 25, in updatefig\n",
        "    image_plot.set_array(img.imread(getImageName(image_number)))\n",
        "  File \"/usr/lib/python2.7/dist-packages/matplotlib/image.py\", line 1323, in imread\n",
        "    with open(fname, 'rb') as fd:\n",
        "IOError: [Errno 2] No such file or directory: '../output/vo_practice_sequence/000701.png'\n"
       ]
      }
     ],
     "prompt_number": 362
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hallway Odometry Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load odometry data from file\n",
      "byu_hallway_data = np.genfromtxt('../output/byu_hallway_sequence_data.txt', delimiter=' ')\n",
      "\n",
      "# Load truth data into list of matricies\n",
      "motion = []\n",
      "for row in byu_hallway_data:\n",
      "    M = np.empty([4, 4])\n",
      "    M[0, 0] = row[0];\n",
      "    M[0, 1] = row[1];\n",
      "    M[0, 2] = row[2];\n",
      "    M[0, 3] = row[3];\n",
      "    M[1, 0] = row[4];\n",
      "    M[1, 1] = row[5];\n",
      "    M[1, 2] = row[6];\n",
      "    M[1, 3] = row[7];\n",
      "    M[2, 0] = row[8];\n",
      "    M[2, 1] = row[9];\n",
      "    M[2, 2] = row[10];\n",
      "    M[2, 3] = row[11];\n",
      "    M[3, 0] = 0;\n",
      "    M[3, 1] = 0;\n",
      "    M[3, 2] = 0;\n",
      "    M[3, 3] = 1;\n",
      "    motion.append(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 374
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(motion)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 375,
       "text": [
        "348"
       ]
      }
     ],
     "prompt_number": 375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create initial camera pose\n",
      "C = np.identity(4)\n",
      "\n",
      "# Create list for saving poses\n",
      "poses = []\n",
      "\n",
      "# Iterate over motion\n",
      "for M in motion:\n",
      "    C = np.matmul(C, inv(M))\n",
      "    #C = np.matmul(C, M)\n",
      "    poses.append(C)\n",
      "\n",
      "# Create lists for x and y coordinates\n",
      "x_hallway = []\n",
      "y_hallway = []\n",
      "z_hallway = []\n",
      "\n",
      "# Start from point 0,0\n",
      "X = np.array([0, 0, 0, 1])\n",
      "X.shape = (4,1)\n",
      "\n",
      "for M in poses:\n",
      "    P = np.matmul(M, X)\n",
      "    #P = np.matmul(inv(M), X)\n",
      "    x_hallway.append(P[2,0])\n",
      "    y_hallway.append(P[1,0])\n",
      "    z_hallway.append(-P[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 376
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot data\n",
      "fig, (ax) = plt.subplots(1, 1, figsize=(9,6))\n",
      "#ax.plot(x_truth, z_truth, 'ro', label='Ground Truth')\n",
      "ax.plot(x_hallway, z_hallway, 'bo', label='Hallway Data')\n",
      "\n",
      "# Label plot\n",
      "ax.set_title('Visual Odometry Track (Hallway)')\n",
      "ax.set_xlabel('x')\n",
      "ax.set_ylabel('z')\n",
      "#ax.legend()\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 377
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Animate Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define animation timing and lenght\n",
      "num_frames = len(x_hallway)\n",
      "frameperioud_msec = 100\n",
      "\n",
      "# Create figures and plots\n",
      "fig2 = plt.figure()\n",
      "ax2 = plt.axes(xlim=(-300, 300), ylim=(-100, 500))\n",
      "#ax2 = plt.axes()\n",
      "#line1, = ax2.plot([], [], 'ro', label='Ground Truth')\n",
      "line2, = ax2.plot([], [], 'bo', label='Hallway Data')\n",
      "\n",
      "def init():\n",
      "    #line1.set_data([], [])\n",
      "    #line2.set_data([], [])\n",
      "    print('made it here 1')\n",
      "    return line1,\n",
      "\n",
      "def animate_odometry(i, x1, z1, x2, z2):\n",
      "    #line1.set_data(x1[1:i], z1[1:i])\n",
      "    line2.set_data(x2[1:i], z2[1:i])\n",
      "    #line1.set_data(x1[i], z1[i])\n",
      "    #line2.set_data(x2[i], z2[i])\n",
      "    return line2,\n",
      "\n",
      "\n",
      "anim = anm.FuncAnimation(fig2, animate_odometry, fargs=(x_truth, z_truth, x_hallway, z_hallway), \n",
      "                         frames=num_frames, interval=frameperioud_msec, blit=True)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 378
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(x_hallway)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 373,
       "text": [
        "2240"
       ]
      }
     ],
     "prompt_number": 373
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}